{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69d569ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db89812",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a5e73",
   "metadata": {},
   "source": [
    "The code provided is a detailed implementation for creating a machine learning-based model that predicts the future stock price movement based on various technical indicators, market regimes, and volatility. Below is a step-by-step breakdown of what each part of the code does:\n",
    "\n",
    "1. Calculating Advanced Technical Indicators:\n",
    "The function calculate_advanced_indicators(df) computes several technical indicators for stock price analysis. These indicators are used in trading algorithms to help identify trends, momentum, and volatility.\n",
    "\n",
    "Moving Averages:\n",
    "EMA (Exponential Moving Average) and WMA (Weighted Moving Average) for various windows (e.g., 5, 10, 20, 50, 100, 200) are calculated to help identify trends and smoothing out fluctuations.\n",
    "Momentum Indicators:\n",
    "ROC (Rate of Change): Measures the percentage change of the stock price over a defined window.\n",
    "MOM (Momentum): Measures the difference between the current price and the price a few periods earlier.\n",
    "Volume-based Indicators:\n",
    "VWAP (Volume-Weighted Average Price): Gives the average price of the stock weighted by its volume over a given window.\n",
    "Volume Force: Measures the influence of volume on momentum.\n",
    "Volatility Measures:\n",
    "ParkinsonVolatility: This volatility measure is based on the high/low prices for the day and captures the price range.\n",
    "Support/Resistance Levels:\n",
    "Calculations for Support and Resistance are done for different window sizes, showing the minimum and maximum price levels over specific periods.\n",
    "Position In Range shows where the current price is in relation to the support/resistance levels, helping to identify whether the price is in a bullish or bearish zone.\n",
    "Enhanced Volatility Features:\n",
    "ATR (Average True Range): Measures volatility by comparing the range between high and low prices.\n",
    "Volatility Ratio: Measures volatility over different time periods, showing the relative volatility between short and long windows.\n",
    "2. Market Regime Features:\n",
    "The function add_market_regime_features(df) adds features that help categorize the market into different \"regimes\" based on volatility and trends.\n",
    "\n",
    "Trend Detection:\n",
    "The code identifies whether the market is in a strong or weak uptrend or downtrend based on comparisons of the current price to moving averages (200-period and 50-period).\n",
    "Volatility Regime:\n",
    "The volatility of the stock is calculated using the percentage change of the stock prices over a rolling window of 21 days.\n",
    "Based on the volatility, the market is categorized into three regimes:\n",
    "0: Low volatility\n",
    "1: Normal volatility\n",
    "2: High volatility\n",
    "3. Creating the Target Variable:\n",
    "The function create_target(df) defines the target variable that the model will predict.\n",
    "\n",
    "Volatility-Adjusted Threshold:\n",
    "The threshold for determining whether the stock's future price return is positive or negative is adjusted dynamically based on volatility. If volatility is high, the threshold is higher, and vice versa.\n",
    "Target Variable (Target):\n",
    "If the return of the stock exceeds the dynamically adjusted threshold, the target is labeled as 1 (indicating a positive price movement); otherwise, it is labeled as 0.\n",
    "4. Creating an Ensemble Model:\n",
    "The function create_ensemble_model() creates an ensemble of two machine learning models:\n",
    "\n",
    "Random Forest Classifier (RandomForestClassifier): A tree-based ensemble model that helps make predictions by aggregating the results of multiple decision trees.\n",
    "Gradient Boosting Classifier (GradientBoostingClassifier): A boosting technique that builds an ensemble of decision trees sequentially, each correcting the errors of the previous one.\n",
    "These models are combined into a Voting Classifier, which predicts based on the majority vote from the two models. The ensemble uses a \"soft\" voting method (probability-based) to combine the predictions, with equal weight given to both models.\n",
    "\n",
    "5. Predicting with Market Regime:\n",
    "The function predict_with_regime(train, test, predictors, model) makes predictions on the test set based on the current market regime.\n",
    "\n",
    "Scaling: The features are standardized using a StandardScaler so that the models can work better.\n",
    "Market Regime-Aware Predictions: The model is trained and tested separately for each of the three volatility regimes (low, normal, high). The predictions are adjusted according to the regime to better fit the market conditions.\n",
    "6. Enhanced Backtesting:\n",
    "The function enhanced_backtest(data, predictors, start=252, step=21) performs backtesting to evaluate the model's performance over time.\n",
    "\n",
    "The backtest is done using a rolling window approach: for each step, the model is trained on a subset of data (up to the current point) and tested on a smaller subsequent subset.\n",
    "The model’s predictions are collected over time, and the results are aggregated.\n",
    "7. Calculating Precision Scores:\n",
    "The main execution part of the code calculates the precision score based on the model’s predictions.\n",
    "\n",
    "Precision Score: Measures how many of the positive predictions are correct (true positives), indicating how accurate the model is when it predicts a positive outcome.\n",
    "Precision by Regime: Precision is calculated separately for each market regime (volatility regime 0, 1, 2) to understand how well the model performs under different market conditions.\n",
    "Main Execution:\n",
    "Download Stock Data: The code retrieves historical data for the stock AAPL using the yfinance library.\n",
    "Feature Engineering: It computes the advanced technical indicators, market regime features, and target variable.\n",
    "Backtesting: It runs an enhanced backtest to predict the stock price movements, considering market regimes.\n",
    "Precision Calculation: Finally, the precision score is computed for the model's overall performance and for each volatility regime.\n",
    "Summary:\n",
    "The code combines machine learning with technical analysis to predict stock price movements by considering both technical indicators and market conditions.\n",
    "It uses an ensemble of models (Random Forest and Gradient Boosting) and trains them under different market regimes to make more accurate predictions.\n",
    "Backtesting is performed to evaluate the model's predictive performance, and precision scores are calculated to assess the accuracy of the model’s positive predictions.\n",
    "Key Features of the Code:\n",
    "Market Regime-Aware Modeling: Predicts based on the current market regime (trend and volatility).\n",
    "Dynamic Thresholds: Adjusts the prediction threshold based on volatility to optimize predictions.\n",
    "Ensemble Model: Uses multiple models to improve prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f82cbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Precision Score: 0.4375\n",
      "Precision Score for Volatility Regime 0: 0.0\n",
      "Precision Score for Volatility Regime 1: 0.4375\n",
      "Precision Score for Volatility Regime 2: 0.0\n"
     ]
    }
   ],
   "source": [
    "def calculate_advanced_indicators(df):\n",
    "    \"\"\"Enhanced technical indicators with market regime detection\"\"\"\n",
    "    # Advanced momentum features\n",
    "    for window in [5, 10, 20, 50, 100, 200]:\n",
    "        # Enhanced moving averages with Wilder's smoothing\n",
    "        df[f'EMA_{window}'] = df['Close'].ewm(span=window, adjust=False).mean()\n",
    "        df[f'WMA_{window}'] = df['Close'].ewm(alpha=1/window, adjust=False).mean()\n",
    "        \n",
    "        # Dynamic momentum indicators\n",
    "        df[f'ROC_{window}'] = df['Close'].pct_change(window) * 100\n",
    "        df[f'MOM_{window}'] = df['Close'].diff(window)\n",
    "        \n",
    "        # Volume-weighted indicators\n",
    "        df[f'VWAP_{window}'] = (df['Close'] * df['Volume']).rolling(window=window).sum() / df['Volume'].rolling(window=window).sum()\n",
    "        df[f'Volume_Force_{window}'] = df['Volume'] * df[f'ROC_{window}']\n",
    "        \n",
    "        # Volatility measures\n",
    "        df[f'ParkinsonVol_{window}'] = np.sqrt(\n",
    "            (1 / (4 * np.log(2))) * \n",
    "            (np.log(df['High'] / df['Low'])**2).rolling(window).mean()\n",
    "        ) * np.sqrt(252)\n",
    "    \n",
    "    # Market regime features\n",
    "    df['Trend_Strength'] = abs(\n",
    "        df['Close'].rolling(20).mean() - df['Close'].rolling(50).mean()\n",
    "    ) / df['Close'].rolling(20).std()\n",
    "    \n",
    "    # Support/Resistance levels\n",
    "    for window in [20, 50, 100]:\n",
    "        df[f'Support_{window}'] = df['Low'].rolling(window=window).min()\n",
    "        df[f'Resistance_{window}'] = df['High'].rolling(window=window).max()\n",
    "        df[f'Position_In_Range_{window}'] = (\n",
    "            (df['Close'] - df[f'Support_{window}']) / \n",
    "            (df[f'Resistance_{window}'] - df[f'Support_{window}'])\n",
    "        )\n",
    "    \n",
    "    # Enhanced volatility features\n",
    "    df['ATR'] = (\n",
    "        df['High'].rolling(14).max() - df['Low'].rolling(14).min()\n",
    "    ) / df['Close'].rolling(14).mean()\n",
    "    \n",
    "    df['Volatility_Ratio'] = (\n",
    "        df['Close'].rolling(10).std() / df['Close'].rolling(30).std()\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_market_regime_features(df):\n",
    "    \"\"\"Detect and encode market regimes\"\"\"\n",
    "    # Trend detection\n",
    "    df['Trend'] = np.where(\n",
    "        df['Close'] > df['Close'].rolling(200).mean(),\n",
    "        np.where(\n",
    "            df['Close'] > df['Close'].rolling(50).mean(),\n",
    "            2,  # Strong uptrend\n",
    "            1   # Weak uptrend\n",
    "        ),\n",
    "        np.where(\n",
    "            df['Close'] < df['Close'].rolling(50).mean(),\n",
    "            -2, # Strong downtrend\n",
    "            -1  # Weak downtrend\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Volatility regime\n",
    "    vol = df['Close'].pct_change().rolling(21).std()\n",
    "    df['Volatility_Regime'] = np.where(\n",
    "        vol > vol.rolling(252).mean() + vol.rolling(252).std(),\n",
    "        2,  # High volatility\n",
    "        np.where(\n",
    "            vol < vol.rolling(252).mean() - vol.rolling(252).std(),\n",
    "            0,  # Low volatility\n",
    "            1   # Normal volatility\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_target(df, volatility_window=20):\n",
    "    \"\"\"Dynamic threshold based on market conditions\"\"\"\n",
    "    # Calculate volatility-adjusted threshold\n",
    "    volatility = df['Close'].pct_change().rolling(volatility_window).std()\n",
    "    base_threshold = 0.015  # 1.5% base threshold\n",
    "    \n",
    "    # Adjust threshold based on volatility regime\n",
    "    df['Dynamic_Threshold'] = base_threshold * (1 + volatility)\n",
    "    \n",
    "    # Create target with dynamic threshold\n",
    "    df['Tomorrow'] = df['Close'].shift(-1)\n",
    "    df['Return'] = (df['Tomorrow'] - df['Close']) / df['Close']\n",
    "    df['Target'] = (df['Return'] > df['Dynamic_Threshold']).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_ensemble_model():\n",
    "    \"\"\"Create an ensemble of different models\"\"\"\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        max_depth=10,\n",
    "        max_features='sqrt',\n",
    "        class_weight={0: 1, 1: 3},\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        min_samples_leaf=15,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    return VotingClassifier(\n",
    "        estimators=[('rf', rf), ('gb', gb)],\n",
    "        voting='soft',\n",
    "        weights=[1, 1]\n",
    "    )\n",
    "\n",
    "def predict_with_regime(train, test, predictors, model, probability_threshold=0.7):\n",
    "    \"\"\"Make predictions considering market regime\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(train[predictors])\n",
    "    test_scaled = scaler.transform(test[predictors])\n",
    "    \n",
    "    # Separate models for different volatility regimes\n",
    "    predictions = pd.Series(index=test.index, dtype=float)\n",
    "    \n",
    "    for regime in [0, 1, 2]:  # Different volatility regimes\n",
    "        regime_mask_train = train['Volatility_Regime'] == regime\n",
    "        regime_mask_test = test['Volatility_Regime'] == regime\n",
    "        \n",
    "        if regime_mask_train.sum() > 50:  # Minimum samples for training\n",
    "            model.fit(\n",
    "                train_scaled[regime_mask_train], \n",
    "                train.loc[regime_mask_train, 'Target']\n",
    "            )\n",
    "            \n",
    "            if regime_mask_test.sum() > 0:\n",
    "                probas = model.predict_proba(test_scaled[regime_mask_test])\n",
    "                # Adjust threshold based on regime\n",
    "                adjusted_threshold = probability_threshold * (1 + regime * 0.1)\n",
    "                predictions[regime_mask_test] = (probas[:, 1] > adjusted_threshold).astype(int)\n",
    "    \n",
    "    return predictions.fillna(0)\n",
    "\n",
    "\n",
    "def enhanced_backtest(data, predictors, start=252, step=21):\n",
    "    \"\"\"Enhanced backtesting with regime-aware predictions\"\"\"\n",
    "    model = create_ensemble_model()\n",
    "    all_predictions = []\n",
    "    \n",
    "    for i in range(start, data.shape[0], step):\n",
    "        train = data.iloc[0:i].copy()\n",
    "        test = data.iloc[i:(i+step)].copy()\n",
    "        predictions = predict_with_regime(train, test, predictors, model)\n",
    "        \n",
    "        # Convert the Series into a DataFrame with column name 'Predictions'\n",
    "        predictions_df = pd.DataFrame(predictions, columns=['Predictions'])\n",
    "        all_predictions.append(predictions_df)\n",
    "    \n",
    "    return pd.concat(all_predictions)\n",
    "\n",
    "# Main execution\n",
    "aapl = yf.Ticker(\"AAPL\")\n",
    "aapl = aapl.history(period=\"max\")\n",
    "\n",
    "# Create enhanced features\n",
    "aapl = calculate_advanced_indicators(aapl)\n",
    "aapl = add_market_regime_features(aapl)\n",
    "aapl = create_target(aapl)\n",
    "aapl = aapl.loc['2017-01-01':].copy()\n",
    "aapl = aapl.dropna()\n",
    "\n",
    "# Define predictors\n",
    "exclude_columns = ['Target', 'Tomorrow', 'Return', 'Open', 'High', 'Low', 'Close', 'Volume', \n",
    "                  'Dynamic_Threshold']\n",
    "predictors = [col for col in aapl.columns if col not in exclude_columns]\n",
    "\n",
    "# Run enhanced backtest\n",
    "predictions = enhanced_backtest(aapl, predictors)\n",
    "\n",
    "# Calculate final precision score\n",
    "final_precision = precision_score(\n",
    "    aapl.iloc[-len(predictions):]['Target'],\n",
    "    predictions['Predictions'].fillna(0)\n",
    ")\n",
    "print(f\"Final Precision Score: {final_precision}\")\n",
    "\n",
    "# Calculate precision by regime\n",
    "for regime in [0, 1, 2]:\n",
    "    regime_mask = aapl['Volatility_Regime'].iloc[-len(predictions):] == regime\n",
    "    if regime_mask.sum() > 0:\n",
    "        regime_precision = precision_score(\n",
    "            aapl.iloc[-len(predictions):]['Target'][regime_mask],\n",
    "            predictions['Predictions'][regime_mask].fillna(0)\n",
    "        )\n",
    "        print(f\"Precision Score for Volatility Regime {regime}: {regime_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee9fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
